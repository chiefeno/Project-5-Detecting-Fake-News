{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting words to use as features\n",
    "In this notebook, we'll be using TFIDF to narrow down the tens of thousands of unique words in our articles and their titles into a more condensed list of important words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Git would not allow us to push a CSV containing the entire dataset so we had to split it up by X and y as well as by train and test sets. Below, we read in all of those files and put them back into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../datasets/X_train_w_SA.csv')\n",
    "X_test = pd.read_csv('../datasets/X_test_w_SA.csv')\n",
    "y_train = pd.read_csv('../datasets/y_train.csv')\n",
    "y_test = pd.read_csv('../datasets/y_test.csv')\n",
    "\n",
    "y_train['train_dataset'] = 1\n",
    "y_test['train_dataset'] = 0\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([X, y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe with all of our vectorized unique words was extremely large so we converted it into a sparse file in order to share it among ourselves in the Github repository. Below, we read in that sparse file and convert it back to a dataframe for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vec = sparse.load_npz('../datasets/sparse_vec_df.npz')\n",
    "vec_df = pd.DataFrame.sparse.from_spmatrix(sparse_vec)\n",
    "vec_df.columns = pd.read_csv('../datasets/vec_df_cols.csv').loc[:,'0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>0</th>\n",
       "      <th>aal</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aba</th>\n",
       "      <th>aback</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>...</th>\n",
       "      <th>zonation</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zu</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39854</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39855</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39858 rows Ã— 28602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      aal  aardvark  aba  aback  abacus  abandon  abandoned  abandoning  \\\n",
       "0        0         0    0      0       0        0          0           0   \n",
       "1        0         0    0      0       0        0          0           0   \n",
       "2        0         0    0      0       0        0          0           0   \n",
       "3        0         0    0      0       0        0          0           0   \n",
       "4        0         0    0      0       0        0          0           0   \n",
       "...    ...       ...  ...    ...     ...      ...        ...         ...   \n",
       "39853    0         0    0      0       0        0          0           0   \n",
       "39854    0         0    0      0       0        0          0           0   \n",
       "39855    0         0    0      0       0        0          0           0   \n",
       "39856    0         0    0      0       0        0          0           0   \n",
       "39857    0         0    0      0       0        0          0           0   \n",
       "\n",
       "0      abandonment  abandons  ...  zonation  zone  zoned  zones  zoning  zoo  \\\n",
       "0                0         0  ...         0     0      0      0       0    0   \n",
       "1                0         0  ...         0     0      0      0       0    0   \n",
       "2                0         0  ...         0     0      0      0       0    0   \n",
       "3                0         0  ...         0     0      0      0       0    0   \n",
       "4                0         0  ...         0     0      0      0       0    0   \n",
       "...            ...       ...  ...       ...   ...    ...    ...     ...  ...   \n",
       "39853            0         0  ...         0     0      0      0       0    0   \n",
       "39854            0         0  ...         0     0      0      0       0    0   \n",
       "39855            0         0  ...         0     0      0      0       0    0   \n",
       "39856            0         0  ...         0     0      0      0       0    0   \n",
       "39857            0         0  ...         0     0      0      0       0    0   \n",
       "\n",
       "0      zoom  zorro  zu  zucchini  \n",
       "0         0      0   0         0  \n",
       "1         0      0   0         0  \n",
       "2         0      0   0         0  \n",
       "3         0      0   0         0  \n",
       "4         0      0   0         0  \n",
       "...     ...    ...  ..       ...  \n",
       "39853     0      0   0         0  \n",
       "39854     0      0   0         0  \n",
       "39855     0      0   0         0  \n",
       "39856     0      0   0         0  \n",
       "39857     0      0   0         0  \n",
       "\n",
       "[39858 rows x 28602 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the most important words, we concatenated the titles with their corresponding text and created a new version of that text where only the stems remained. We then vectorized again to find the frequency and importance of use for each stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating titles and text\n",
    "df['all_text'] = [np.nan]*df.shape[0]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    text = df.loc[i, 'text']\n",
    "    title = df.loc[i, 'title']\n",
    "    all_text = title + ' ' + text\n",
    "    df.loc[i,'all_text'] = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating stemmer and creating a list of real words\n",
    "stemmer = PorterStemmer()\n",
    "word_list = vec_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n"
     ]
    }
   ],
   "source": [
    "# creating a column for the stemmed versions of the text\n",
    "df['stemmed'] = [np.nan]*df.shape[0]\n",
    "\n",
    "# concatenating stems from text into strings in the stemmed column\n",
    "for i, t in enumerate(list(df['all_text'])):\n",
    "    stemmed = []\n",
    "    for word in t.split(' '):\n",
    "        if word.lower() in word_list:\n",
    "            stem = stemmer.stem(word)\n",
    "            stemmed.append(stem)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    df.loc[i,'stemmed'] = ' '.join(stemmed)\n",
    "    if (i % 3000) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we vectorize the text again so we have a dataframe of only the stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(df['stemmed'])\n",
    "\n",
    "words_cv = cv.transform(df['stemmed'])\n",
    "\n",
    "stems_df = pd.DataFrame(words_cv.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the importance of words in one \"document\" relative to another (in this case, one document is fake news and the other is real news), we concatenated all of the stemmed text into two long strings, one for each class and compared those to one another. The result was a dataframe with the stems and their relative importance to each \"document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_string = ''\n",
    "f_string = ''\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    string = df.loc[i,'stemmed']\n",
    "    if df.loc[i,'is_true'] == 1:\n",
    "        r_string += ' '+string\n",
    "    else: \n",
    "        f_string += ' '+string\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tvec.fit([r_string,f_string])\n",
    "\n",
    "tv = pd.DataFrame(tvec.transform([r_string, f_string]).todense(),\n",
    "                   columns=tvec.get_feature_names(),\n",
    "                   index=['real', 'fake'])\n",
    "\n",
    "tv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then utilized this dataframe to capture the most important words from each document as our features. We set a threshold of 0.01 in order to narrow the words down and got a list of 577 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_t = tv.T\n",
    "\n",
    "r_words = set(tv_t[tv_t['fake'] > 0.01].index)\n",
    "f_words = set(tv_t[tv_t['fake'] > 0.01].index)\n",
    "selected_words = list(r_words.union(f_words))\n",
    "selected_words.sort()\n",
    "len(selected_words)a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those selected words, we narrowed dataframe and added those 577 columns into the same dataframe as our engineered features relating to punctuation, sentiment, or parts of speech. In total, we had a dataframe with our approximately 40,000 samples and 626 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.merge(stems_df[selected_words], right_index = True, left_index = True)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the punctuation, sentiment, and parts of speech columns\n",
    "feats = list(full_df.columns[3:52])\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding all of our selected words for a full list of our features\n",
    "feats.extend(selected_words)\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting new X_train and X_test CSVs with our chosen features\n",
    "full_df.loc[full_df['train_dataset'] == 1, feats].to_csv('../datasets/X_train_w_SA_and_words.csv', index = False)\n",
    "full_df.loc[full_df['train_dataset'] == 0, feats].to_csv('../datasets/X_test_w_SA_and_words.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
